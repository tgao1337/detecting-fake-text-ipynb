{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import kstest\n",
    "\n",
    "\n",
    "def get_top_k_count(real_topk, top1 = 10, top2 = 100, top3 = 1000):\n",
    "    # takes in the json part for real_topk and returns the counts of top1,2,3,4\n",
    "    # top4 is just whatever is past the last number, for example >1000\n",
    "    # returns list in order of top1 to top4 bins\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    t3 = 0\n",
    "    t4 = 0\n",
    "    for item in real_topk:\n",
    "        if(item[0] < top1):\n",
    "            t1 = t1 + 1\n",
    "        elif(item[0] < top2):\n",
    "            t2 = t2 + 1\n",
    "        elif(item[0] < top3):\n",
    "            t3 = t3 + 1\n",
    "        else:\n",
    "            t4 = t4 + 1\n",
    "    return [t1, t2, t3, t4]\n",
    "\n",
    "\n",
    "def get_top_k_count_from_file(json_file, top1 = 10, top2 = 100, top3 = 1000):\n",
    "    # takes in the json file and returns the counts of top1,2,3,4\n",
    "    # top4 is just whatever is past the last number, for example >1000\n",
    "    # returns list in order of top1 to top4 bins\n",
    "    return get_top_k_count(json_file[\"result\"][\"real_topk\"], top1, top2, top3)\n",
    "\n",
    "\n",
    "def get_frac_p(real_topk, pred_topk):\n",
    "    # takes in real_topk and pred_topk and returns list of\n",
    "    # frac(p)\n",
    "    res = []\n",
    "    for i in range(len(real_topk)):\n",
    "        res.append(real_topk[i][1] / pred_topk[i][0][1])\n",
    "    return res\n",
    "\n",
    "\n",
    "def fracp_bin_counter(fracp):\n",
    "    # takes in the list of all frac(p) and returns list of buckets from 0-1\n",
    "    # counting by 0.1\n",
    "    b0 = 0\n",
    "    b1 = 0\n",
    "    b2 = 0\n",
    "    b3 = 0\n",
    "    b4 = 0\n",
    "    b5 = 0\n",
    "    b6 = 0\n",
    "    b7 = 0\n",
    "    b8 = 0\n",
    "    b9 = 0\n",
    "\n",
    "    for val in fracp:\n",
    "        if(val <= 0.1):\n",
    "            b0 = b0 + 1\n",
    "        elif(val <= 0.2):\n",
    "            b1 = b1 + 1\n",
    "        elif(val <= 0.3):\n",
    "            b2 = b2 + 1\n",
    "        elif (val <= 0.4):\n",
    "            b3 = b3 + 1\n",
    "        elif (val <= 0.5):\n",
    "            b4 = b4 + 1\n",
    "        elif (val <= 0.6):\n",
    "            b5 = b5 + 1\n",
    "        elif (val <= 0.7):\n",
    "            b6 = b6 + 1\n",
    "        elif (val <= 0.8):\n",
    "            b7 = b7 + 1\n",
    "        elif (val <= 0.9):\n",
    "            b8 = b8 + 1\n",
    "        else:\n",
    "            b9 = b9 + 1\n",
    "    # print([b0, b1, b2, b3, b4, b5, b6, b7, b8, b9])\n",
    "    return [b0, b1, b2, b3, b4, b5, b6, b7, b8, b9]\n",
    "\n",
    "\n",
    "def fracp_bin_counter_from_file(json_file):\n",
    "    # takes json file (json structure) and returns bins count\n",
    "    rtk = json_file[\"result\"][\"real_topk\"]\n",
    "    ptk = json_file[\"result\"][\"pred_topk\"]\n",
    "    return fracp_bin_counter(get_frac_p(rtk, ptk))\n",
    "\n",
    "\n",
    "def zero_to_small_num(lst):\n",
    "    # takes a list and replaces all 0 with a small number\n",
    "    for i in range(len(lst)):\n",
    "        if lst[i] == 0:\n",
    "            lst[i] = 0.0000000000000000000001\n",
    "    return lst\n",
    "\n",
    "\n",
    "def get_kld(fp_bin1, fp_bin2):\n",
    "    # given two list of bin counts (10 long by default)\n",
    "    # returns KLD value\n",
    "    return entropy(fp_bin1, fp_bin2)\n",
    "\n",
    "\n",
    "def get_kld_from_json_file(file1, file2):\n",
    "    # given two json objects\n",
    "    # returns KLD value\n",
    "    # this skips a lot of steps to make it easier\n",
    "    realtk_1 = file1[\"result\"][\"real_topk\"]\n",
    "    predtk_1 = file1[\"result\"][\"pred_topk\"]\n",
    "    realtk_2 = file2[\"result\"][\"real_topk\"]\n",
    "    predtk_2 = file2[\"result\"][\"pred_topk\"]\n",
    "\n",
    "    bins1 = fracp_bin_counter(get_frac_p(realtk_1, predtk_1))\n",
    "    bins2 = fracp_bin_counter(get_frac_p(realtk_2, predtk_2))\n",
    "    print(str(bins1) + \"                   \" + str(bins2))\n",
    "    # bins1 = zero_to_small_num(bins1)\n",
    "    # bins2 = zero_to_small_num(bins2)\n",
    "    print(str(bins1) + \"                   \" + str(bins2))\n",
    "    return get_kld(bins1, bins2)\n",
    "\n",
    "\n",
    "def get_jsd(fp_bin1, fp_bin2):\n",
    "    # given two list of bin counts, (10 long by default)\n",
    "    # returns JSD value\n",
    "    return distance.jensenshannon(fp_bin1, fp_bin2)\n",
    "\n",
    "\n",
    "def compare_json_files_kld(filename1, filename2):\n",
    "    # given two file names, get json from it, then use kld\n",
    "    # returns list of all kld values\n",
    "    lst = []\n",
    "    with open(filename1) as f1:\n",
    "        d1 = json.load(f1)\n",
    "    with open(filename2) as f2:\n",
    "        d2 = json.load(f2)\n",
    "    print(str(len(d1))+\"       F2:\"+str(len(d2)))\n",
    "\n",
    "    for d1x in d1:\n",
    "        for d2x in d2:\n",
    "            # print(\"D1: \" + str(d1x) + \"           D2: \" + str(d2x))\n",
    "            lst.append(get_kld_from_json_file(d1x, d2x))\n",
    "            print(lst[-1])\n",
    "    return lst\n",
    "\n",
    "\n",
    "def list_of_fracp_from_file(filename):\n",
    "    # given two file names, get json from it, then return list\n",
    "    # returns list of list of 10 frac p bins\n",
    "    lst = []\n",
    "    with open(filename) as f1:\n",
    "        d1 = json.load(f1)\n",
    "\n",
    "    for d1x in d1:\n",
    "        lst.append(fracp_bin_counter_from_file(d1x))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def list_of_fracp_from_jsonl_file(filename):\n",
    "    # given two file names of json lines, get json from it, then return list\n",
    "    # returns list of list of 10 frac p bins\n",
    "    lst = []\n",
    "    with jsonlines.open(filename) as reader:\n",
    "        for obj in reader:\n",
    "            lst.append(fracp_bin_counter_from_file(obj))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def list_of_norm_fracp_from_file(filename):\n",
    "    # given two file names, get json from it, then return list\n",
    "    # returns list of list of 10 frac p bins that are normalized\n",
    "    lst = []\n",
    "    with open(filename) as f1:\n",
    "        d1 = json.load(f1)\n",
    "\n",
    "    for d1x in d1:\n",
    "        bins = fracp_bin_counter_from_file(d1x)\n",
    "        tot = sum(bins)\n",
    "        for i in range(10):\n",
    "            bins[i] = bins[i] / tot\n",
    "        print(sum(bins))\n",
    "        lst.append(bins)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of pickles to use\n",
    "- \"fracp.GPT2-human-25000-pd-normalized.pickle\"\n",
    "- \"fracp.GPT2-machine-25000-pd-normalized.pickle\"\n",
    "- \"fracp.GROVER-human-15000-pd-normalized.pickle\"\n",
    "- \"fracp.GROVER-machine-10000-pd-normalized.pickle\"\n",
    "- \"fracp.GPT3-machine-485-pd-normalized.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "0      0.209524  0.061905  0.047619  0.023810  0.047619  0.023810  0.009524   \n",
      "1      0.277978  0.106498  0.055957  0.043321  0.028881  0.034296  0.023466   \n",
      "2      0.274725  0.098901  0.054945  0.071429  0.016484  0.038462  0.038462   \n",
      "3      0.254296  0.092784  0.054983  0.037801  0.034364  0.027491  0.030928   \n",
      "4      0.211009  0.082569  0.055046  0.036697  0.027523  0.027523  0.045872   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "24994  0.328859  0.134228  0.060403  0.040268  0.040268  0.020134  0.033557   \n",
      "24995  0.290055  0.096685  0.049724  0.041436  0.052486  0.038674  0.024862   \n",
      "24996  0.265734  0.087413  0.055944  0.050117  0.025641  0.022145  0.025641   \n",
      "24997  0.230769  0.089397  0.058212  0.035343  0.037422  0.039501  0.018711   \n",
      "24998  0.250399  0.108453  0.060606  0.051037  0.043062  0.044657  0.022329   \n",
      "\n",
      "              7         8         9  \n",
      "0      0.033333  0.028571  0.514286  \n",
      "1      0.016245  0.016245  0.397112  \n",
      "2      0.021978  0.010989  0.373626  \n",
      "3      0.013746  0.017182  0.436426  \n",
      "4      0.018349  0.018349  0.477064  \n",
      "...         ...       ...       ...  \n",
      "24994  0.006711  0.013423  0.322148  \n",
      "24995  0.013812  0.016575  0.375691  \n",
      "24996  0.015152  0.015152  0.437063  \n",
      "24997  0.027027  0.016632  0.446985  \n",
      "24998  0.031898  0.014354  0.373206  \n",
      "\n",
      "[24999 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "observed = pd.read_pickle(\"fracp.GPT2-machine-25000-pd-normalized.pickle\")\n",
    "print(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=0.031895314243821415, pvalue=0.999999999845967)\n"
     ]
    }
   ],
   "source": [
    "observed = pd.read_pickle(\"fracp.GPT2-machine-25000-pd-normalized.pickle\").mean(axis=0)\n",
    "expected = pd.read_pickle(\"fracp.GPT2-human-25000-pd-normalized.pickle\").replace(0, 0.00000000000000000000000000000001).mean(axis=0)\n",
    "chi_res = chisquare(observed, expected, 0, 0)\n",
    "print(chi_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
